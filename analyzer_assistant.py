import os
import json
import time
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
from assistant_config import load_assistant_ids

load_dotenv()
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    default_headers={"OpenAI-Beta": "assistants=v2"}
)

OUTPUT_FILE = "output/analysis_result_interactive.json"
os.makedirs("output", exist_ok=True)

def extract_region_table(df, start_row, end_row, header_row):
    header = df.iloc[header_row - 1]
    data = df.iloc[start_row - 1:end_row].copy()
    data.columns = header
    data = data.reset_index(drop=True)
    return data

def analyze_section_by_column(markdown_table, assistant_id, group_by_column):
    thread = client.beta.threads.create()
    prompt = (
        f"T√¥i g·ª≠i b·∫°n b·∫£ng d·ªØ li·ªáu d·∫°ng markdown b√™n d∆∞·ªõi.\n"
        f"H√£y ph√¢n t√≠ch b·∫£ng n√†y theo c·ªôt **'{group_by_column}'** b·∫±ng c√°ch:\n"
        "- Nh√≥m theo c·ªôt ƒë√≥ (`group_by`)\n"
        "- Sinh b·∫£ng t·ªïng h·ª£p v√† m√¥ t·∫£ ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát\n"
        "Tr·∫£ v·ªÅ ƒë√∫ng ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá, kh√¥ng k√®m m√¥ t·∫£, kh√¥ng b·ªçc markdown. V√≠ d·ª•:\n"
        "{\"group_by\": \"T√™n nh√¢n vi√™n\", \"summary_table\": \"| T√™n | S·ªë c√¥ng |...\", \"description\": \"M√¥ t·∫£ ng·∫Øn\"}\n\n"
        f"{markdown_table}"
    )
    client.beta.threads.messages.create(thread_id=thread.id, role="user", content=prompt)
    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id)

    while True:
        status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
        if status.status == "completed":
            break
        elif status.status == "failed":
            raise Exception("‚ùå Assistant th·∫•t b·∫°i.")
        time.sleep(1)

    messages = client.beta.threads.messages.list(thread_id=thread.id)
    for msg in reversed(messages.data):
        for part in msg.content:
            if part.type == "text":
                text = part.text.value.strip().strip("`").strip()
                print("üì© Assistant tr·∫£ v·ªÅ:", text)
                if text.startswith("{") and text.endswith("}"):
                    try:
                        return json.loads(text)
                    except Exception as e:
                        print("‚ùå JSON decode error:", e)
    raise ValueError("‚ùå Kh√¥ng t√¨m th·∫•y JSON k·∫øt qu·∫£.")

def run_analyzer(file_path: str, extracted_path: str):
    if not os.path.exists(file_path) or not os.path.exists(extracted_path):
        print("‚ùå Thi·∫øu file Excel ho·∫∑c extracted_sections.json.")
        return

    assistant_id = load_assistant_ids()["analyzer_id"]
    df = pd.read_excel(file_path)
    with open(extracted_path, "r", encoding="utf-8") as f:
        extracted = json.load(f)

    results = {}

    for region_id, region in extracted["regions"].items():
        print(f"üîç ƒêang ph√¢n t√≠ch {region_id}...")
        try:
            region_df = extract_region_table(
                df,
                region["start_row"],
                region["end_row"],
                region["header_row"]
            )
            print(f"üìã C√°c c·ªôt trong {region_id}:", list(region_df.columns))
            group_by = input(f"üß≠ Nh·∫≠p t√™n c·ªôt mu·ªën group_by cho {region_id}: ").strip()
            markdown = region_df.head(100).to_markdown(index=False)
            analysis = analyze_section_by_column(markdown, assistant_id, group_by)
            results[region_id] = analysis
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω {region_id}:", e)

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {OUTPUT_FILE}")
